name: Manual Glicko Pipeline Run

on:
  workflow_dispatch:
    inputs:
      first_month:
        description: 'First month to process (YYYY-MM format)'
        required: true
        default: '2025-07'
      last_month:
        description: 'Last month to process (YYYY-MM format)'
        required: true
        default: '2025-07'
      task_cpu:
        description: 'CPU units (1024 = 1 vCPU)'
        required: false
        default: '1024'
      task_memory:
        description: 'Memory in MiB'
        required: false
        default: '2048'
      pipeline_mode:
        description: 'Pipeline mode to run'
        required: false
        default: 'full'
        type: choice
        options:
        - 'full'
        - 'post_scraping'

env:
  AWS_REGION: ${{ secrets.AWS_REGION }}
  PROJECT_NAME: chess-glicko

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Validate Month Format
      run: |
        if [[ ! "${{ github.event.inputs.first_month }}" =~ ^[0-9]{4}-[0-9]{2}$ ]]; then
          echo "Error: First month must be in YYYY-MM format"
          exit 1
        fi
        if [[ ! "${{ github.event.inputs.last_month }}" =~ ^[0-9]{4}-[0-9]{2}$ ]]; then
          echo "Error: Last month must be in YYYY-MM format"
          exit 1
        fi
        
        # Validate that first_month <= last_month
        if [[ "${{ github.event.inputs.first_month }}" > "${{ github.event.inputs.last_month }}" ]]; then
          echo "Error: First month must be less than or equal to last month"
          exit 1
        fi

    - name: Generate Month Range
      id: months
      run: |
        echo "=== Generating Month Range ==="
        
        # Parse input dates
        FIRST_MONTH="${{ github.event.inputs.first_month }}"
        LAST_MONTH="${{ github.event.inputs.last_month }}"
        
        echo "Processing from $FIRST_MONTH to $LAST_MONTH"
        
        # Convert dates to comparable format (YYYYMM)
        FIRST_NUMERIC=$(echo $FIRST_MONTH | tr -d '-')
        LAST_NUMERIC=$(echo $LAST_MONTH | tr -d '-')
        
        # Generate list of months
        MONTHS=""
        CURRENT_MONTH="$FIRST_MONTH"
        CURRENT_NUMERIC="$FIRST_NUMERIC"
        
        while [[ $CURRENT_NUMERIC -le $LAST_NUMERIC ]]; do
          if [[ -n "$MONTHS" ]]; then
            MONTHS="$MONTHS $CURRENT_MONTH"
          else
            MONTHS="$CURRENT_MONTH"
          fi
          
          # Break if we've reached the last month
          if [[ "$CURRENT_MONTH" == "$LAST_MONTH" ]]; then
            break
          fi
          
          # Calculate next month
          YEAR=$(echo $CURRENT_MONTH | cut -d'-' -f1)
          MONTH=$(echo $CURRENT_MONTH | cut -d'-' -f2)
          
          # Increment month
          MONTH=$((10#$MONTH + 1))
          
          # Handle year rollover
          if [[ $MONTH -gt 12 ]]; then
            MONTH=1
            YEAR=$((YEAR + 1))
          fi
          
          # Format next month
          CURRENT_MONTH=$(printf "%04d-%02d" $YEAR $MONTH)
          CURRENT_NUMERIC=$(echo $CURRENT_MONTH | tr -d '-')
        done
        
        echo "months=$MONTHS" >> $GITHUB_OUTPUT
        echo "Months to process: $MONTHS"
        
        # Count months for logging
        MONTH_COUNT=$(echo $MONTHS | wc -w)
        echo "month_count=$MONTH_COUNT" >> $GITHUB_OUTPUT
        echo "Total months to process: $MONTH_COUNT"

    - name: Get Infrastructure Details
      id: infra
      run: |
        echo "=== Getting Infrastructure Details ==="
        
        # Get cluster name
        CLUSTER_NAME=$(aws ecs list-clusters \
          --query "clusterArns[?contains(@, '${{ env.PROJECT_NAME }}')]" \
          --output text | cut -d'/' -f2)
        
        if [ -z "$CLUSTER_NAME" ]; then
          echo "‚ö†Ô∏è  No cluster found with project name, using default: chess-glicko-cluster"
          CLUSTER_NAME="chess-glicko-cluster"
        fi
        echo "cluster_name=$CLUSTER_NAME" >> $GITHUB_OUTPUT
        echo "Using cluster: $CLUSTER_NAME"
        
        # Get task definition
        TASK_DEF=$(aws ecs list-task-definitions \
          --family-prefix ${{ env.PROJECT_NAME }} \
          --sort DESC \
          --max-items 1 \
          --query 'taskDefinitionArns[0]' \
          --output text | cut -d'/' -f2 | cut -d':' -f1)
        
        if [ -z "$TASK_DEF" ] || [ "$TASK_DEF" = "None" ]; then
          echo "‚ö†Ô∏è  No task definition found with project name, using default: chess-glicko-task"
          TASK_DEF="chess-glicko-task"
        fi
        echo "task_definition=$TASK_DEF" >> $GITHUB_OUTPUT
        echo "Using task definition: $TASK_DEF"
        
        # Get S3 bucket name
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        S3_BUCKET_NAME="${{ env.PROJECT_NAME }}-data-$ACCOUNT_ID"
        echo "s3_bucket_name=$S3_BUCKET_NAME" >> $GITHUB_OUTPUT
        echo "Using S3 bucket: $S3_BUCKET_NAME"
        
        # Get network configuration - multiple subnets for better availability
        SUBNET_IDS=$(aws ec2 describe-subnets \
          --filters "Name=vpc-id,Values=$(aws ec2 describe-vpcs --filters 'Name=isDefault,Values=true' --query 'Vpcs[0].VpcId' --output text)" \
          --query 'Subnets[0:3].SubnetId' \
          --output text | tr '\t' ',')
        echo "subnet_ids=$SUBNET_IDS" >> $GITHUB_OUTPUT
        echo "Using subnets: $SUBNET_IDS"
        
        # Get security group
        SG_ID=$(aws ec2 describe-security-groups \
          --filters "Name=group-name,Values=chess-glicko-ecs-tasks" \
          --query 'SecurityGroups[0].GroupId' \
          --output text 2>/dev/null || echo "")
        
        if [ -z "$SG_ID" ] || [ "$SG_ID" = "None" ]; then
          SG_ID=$(aws ec2 describe-security-groups \
            --filters "Name=group-name,Values=default" \
            --query 'SecurityGroups[0].GroupId' \
            --output text)
          echo "‚ö†Ô∏è  Using default security group: $SG_ID"
        else
          echo "Using project security group: $SG_ID"
        fi
        echo "security_group_id=$SG_ID" >> $GITHUB_OUTPUT

    - name: Run Pipeline for Each Month
      id: pipeline_run
      env:
        CLUSTER_NAME: ${{ steps.infra.outputs.cluster_name }}
        TASK_DEFINITION: ${{ steps.infra.outputs.task_definition }}
        S3_BUCKET_NAME: ${{ steps.infra.outputs.s3_bucket_name }}
        SUBNET_IDS: ${{ steps.infra.outputs.subnet_ids }}
        SECURITY_GROUP_ID: ${{ steps.infra.outputs.security_group_id }}
        MONTHS: ${{ steps.months.outputs.months }}
        MONTH_COUNT: ${{ steps.months.outputs.month_count }}
      run: |
        echo "=== Running ${{ github.event.inputs.pipeline_mode }} Pipeline for Multiple Months ==="
        echo "Date range: ${{ github.event.inputs.first_month }} to ${{ github.event.inputs.last_month }}"
        echo "Total months: $MONTH_COUNT"
        echo "Mode: ${{ github.event.inputs.pipeline_mode }}"
        echo "CPU: ${{ github.event.inputs.task_cpu }}"
        echo "Memory: ${{ github.event.inputs.task_memory }}"
        echo "Cluster: $CLUSTER_NAME"
        echo "Task Definition: $TASK_DEFINITION"
        echo "S3 Bucket: $S3_BUCKET_NAME"
        echo "Subnets: $SUBNET_IDS"
        echo "Security Group: $SECURITY_GROUP_ID"
        echo ""
        
        # Store pipeline start time for monitoring
        PIPELINE_START_TIME=$(date -u +%Y-%m-%dT%H:%M:%S)
        echo "pipeline_start_time=$PIPELINE_START_TIME" >> $GITHUB_OUTPUT
        
        # Prepare pipeline mode description
        if [ "${{ github.event.inputs.pipeline_mode }}" = "full" ]; then
          echo "üìä Full pipeline will run all steps for each month:"
          echo "  - Download data archives"
          echo "  - Extract and process games"
          echo "  - Calculate Glicko ratings"
          echo "  - Upload results to S3"
          ESTIMATED_TIME_PER_MONTH=17
          echo "  ‚ö†Ô∏è  Expected duration per month: 15-20 minutes"
        else
          echo "üìä Post-scraping pipeline will run for each month:"
          echo "  - Process calculation data"
          echo "  - Calculate Glicko ratings"
          echo "  - Upload results to S3"
          ESTIMATED_TIME_PER_MONTH=3
          echo "  ‚ö†Ô∏è  Expected duration per month: 2-5 minutes"
        fi
        
        TOTAL_ESTIMATED_TIME=$((ESTIMATED_TIME_PER_MONTH * MONTH_COUNT))
        echo "  üïê Total estimated time: ~$TOTAL_ESTIMATED_TIME minutes"
        echo ""
        
        # Track results
        SUCCESSFUL_MONTHS=""
        FAILED_MONTHS=""
        CURRENT_MONTH_NUM=1
        ALL_TASK_ARNS=""
        
        # Process each month
        for MONTH in $MONTHS; do
          echo "=================================="
          echo "üóìÔ∏è  Processing month $CURRENT_MONTH_NUM of $MONTH_COUNT: $MONTH"
          echo "=================================="
          
          # Run the task
          echo "Starting pipeline task for $MONTH..."
          TASK_ARN=$(aws ecs run-task \
            --cluster $CLUSTER_NAME \
            --task-definition $TASK_DEFINITION \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_IDS],assignPublicIp=ENABLED,securityGroups=[$SECURITY_GROUP_ID]}" \
            --overrides "{
              \"taskRoleArn\": \"$(aws ecs describe-task-definition --task-definition $TASK_DEFINITION --query 'taskDefinition.taskRoleArn' --output text)\",
              \"cpu\": \"${{ github.event.inputs.task_cpu }}\",
              \"memory\": \"${{ github.event.inputs.task_memory }}\",
              \"containerOverrides\": [{
                \"name\": \"chess-glicko\",
                \"environment\": [{
                  \"name\": \"PROCESS_MONTH\",
                  \"value\": \"$MONTH\"
                }, {
                  \"name\": \"PIPELINE_MODE\",
                  \"value\": \"${{ github.event.inputs.pipeline_mode }}\"
                }, {
                  \"name\": \"S3_BUCKET\",
                  \"value\": \"$S3_BUCKET_NAME\"
                }]
              }]
            }" \
            --query 'tasks[0].taskArn' \
            --output text)
          
          if [ -n "$TASK_ARN" ] && [ "$TASK_ARN" != "None" ]; then
            echo "‚úÖ Pipeline task started successfully for $MONTH!"
            echo "Task ARN: $TASK_ARN"
            
            # Store task ARN for monitoring
            ALL_TASK_ARNS="$ALL_TASK_ARNS $TASK_ARN"
            
            # Wait for task to complete - increased to 1 hour (3600 seconds)
            echo "‚è≥ Waiting for task to complete..."
            TASK_STATUS="RUNNING"
            MAX_WAIT_TIME=3600  # 1 hour max wait
            WAIT_TIME=0
            
            while [[ "$TASK_STATUS" != "STOPPED" && $WAIT_TIME -lt $MAX_WAIT_TIME ]]; do
              sleep 30
              WAIT_TIME=$((WAIT_TIME + 30))
              TASK_STATUS=$(aws ecs describe-tasks \
                --cluster "$CLUSTER_NAME" \
                --tasks "$TASK_ARN" \
                --query 'tasks[0].lastStatus' \
                --output text 2>/dev/null || echo "UNKNOWN")
              
              if [[ $((WAIT_TIME % 300)) -eq 0 ]]; then  # Log every 5 minutes
                echo "‚è≥ Task still running after $((WAIT_TIME / 60)) minutes... (Status: $TASK_STATUS)"
              fi
            done
            
            # Check final status
            if [[ "$TASK_STATUS" = "STOPPED" ]]; then
              EXIT_CODE=$(aws ecs describe-tasks \
                --cluster "$CLUSTER_NAME" \
                --tasks "$TASK_ARN" \
                --query 'tasks[0].containers[0].exitCode' \
                --output text 2>/dev/null || echo "unknown")
              
              if [[ "$EXIT_CODE" = "0" ]]; then
                echo "‚úÖ Task completed successfully for $MONTH!"
                SUCCESSFUL_MONTHS="$SUCCESSFUL_MONTHS $MONTH"
              else
                echo "‚ùå Task failed for $MONTH (Exit code: $EXIT_CODE)"
                STOP_REASON=$(aws ecs describe-tasks \
                  --cluster "$CLUSTER_NAME" \
                  --tasks "$TASK_ARN" \
                  --query 'tasks[0].stoppedReason' \
                  --output text 2>/dev/null || echo "unknown")
                echo "Stop reason: $STOP_REASON"
                FAILED_MONTHS="$FAILED_MONTHS $MONTH"
              fi
            else
              echo "‚ùå Task timed out for $MONTH (waited $((WAIT_TIME / 60)) minutes)"
              FAILED_MONTHS="$FAILED_MONTHS $MONTH"
            fi
          else
            echo "‚ùå Failed to start pipeline task for $MONTH"
            echo "Task ARN: '$TASK_ARN'"
            FAILED_MONTHS="$FAILED_MONTHS $MONTH"
          fi
          
          CURRENT_MONTH_NUM=$((CURRENT_MONTH_NUM + 1))
          echo ""
        done
        
        # Store results for monitoring
        echo "task_arns=$ALL_TASK_ARNS" >> $GITHUB_OUTPUT
        echo "successful_months=$SUCCESSFUL_MONTHS" >> $GITHUB_OUTPUT
        echo "failed_months=$FAILED_MONTHS" >> $GITHUB_OUTPUT
        
        echo "=================================="
        echo "üìä FINAL RESULTS"
        echo "=================================="
        echo "Total months processed: $MONTH_COUNT"
        
        if [[ -n "$SUCCESSFUL_MONTHS" ]]; then
          SUCCESSFUL_COUNT=$(echo $SUCCESSFUL_MONTHS | wc -w)
          echo "‚úÖ Successful months ($SUCCESSFUL_COUNT):$SUCCESSFUL_MONTHS"
        fi
        
        if [[ -n "$FAILED_MONTHS" ]]; then
          FAILED_COUNT=$(echo $FAILED_MONTHS | wc -w)
          echo "‚ùå Failed months ($FAILED_COUNT):$FAILED_MONTHS"
          echo ""
          echo "üîó Check logs for failed months:"
          echo "  - CloudWatch Logs: https://console.aws.amazon.com/cloudwatch/home?region=${{ env.AWS_REGION }}#logsV2:log-groups/log-group/%2Fecs%2F${{ env.PROJECT_NAME }}"
          exit 1
        else
          echo "üéâ All months processed successfully!"
        fi

    - name: Monitor Resource Usage and Performance
      if: always()
      env:
          CLUSTER_NAME: ${{ steps.infra.outputs.cluster_name }}
          TASK_DEFINITION: ${{ steps.infra.outputs.task_definition }}
          PIPELINE_START_TIME: ${{ steps.pipeline_run.outputs.pipeline_start_time }}
          TASK_ARNS: ${{ steps.pipeline_run.outputs.task_arns }}
          SUCCESSFUL_MONTHS: ${{ steps.pipeline_run.outputs.successful_months }}
          FAILED_MONTHS: ${{ steps.pipeline_run.outputs.failed_months }}
      run: |
          echo "=== Resource Usage and Performance Monitoring ==="
          echo "Pipeline run period: $PIPELINE_START_TIME to $(date -u +%Y-%m-%dT%H:%M:%S)"
          echo ""
          
          # Use portable date calculations
          if command -v gdate >/dev/null 2>&1; then
            DATE_CMD="gdate"
          else
            DATE_CMD="date"
          fi
          
          # Calculate monitoring time window (add 10 minutes buffer)
          if [ -n "$PIPELINE_START_TIME" ]; then
            START_EPOCH=$(${DATE_CMD} -u -d "$PIPELINE_START_TIME" +%s 2>/dev/null || echo "")
            if [ -n "$START_EPOCH" ]; then
              START_TIME=$(${DATE_CMD} -u -d "@$((START_EPOCH - 600))" +%Y-%m-%dT%H:%M:%S 2>/dev/null || echo "$PIPELINE_START_TIME")
            else
              START_TIME="$PIPELINE_START_TIME"
            fi
          else
            START_TIME=$(${DATE_CMD} -u -d "1 hour ago" +%Y-%m-%dT%H:%M:%S 2>/dev/null || ${DATE_CMD} -u +%Y-%m-%dT%H:%M:%S)
          fi
          
          END_TIME=$(${DATE_CMD} -u +%Y-%m-%dT%H:%M:%S)
          
          echo "üìä Monitoring time window: $START_TIME to $END_TIME"
          echo ""
          
          # Check if CloudWatch metrics are available
          echo "üñ•Ô∏è  CLUSTER METRICS"
          echo "==================="
          
          # CPU Utilization with error handling
          echo "üìà CPU Utilization (%):"
          CPU_STATS=$(aws cloudwatch get-metric-statistics \
            --namespace AWS/ECS \
            --metric-name CPUUtilization \
            --dimensions Name=ClusterName,Value="$CLUSTER_NAME" \
            --start-time "$START_TIME" \
            --end-time "$END_TIME" \
            --period 300 \
            --statistics Average,Maximum,Minimum \
            --query 'Datapoints[*].[Timestamp,Average,Maximum,Minimum]' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$CPU_STATS" ] && [ "$CPU_STATS" != "None" ]; then
            echo "$CPU_STATS" | sort | tail -10 | while read timestamp avg max min; do
              if [ -n "$timestamp" ] && [ "$timestamp" != "None" ]; then
                TIME_DISPLAY=$(${DATE_CMD} -d "$timestamp" '+%H:%M:%S' 2>/dev/null || echo "$timestamp")
                printf "  %s: Avg=%.1f%%, Max=%.1f%%, Min=%.1f%%\n" "$TIME_DISPLAY" "$avg" "$max" "$min"
              fi
            done
          else
            echo "  No CPU metrics available for the specified time range"
            echo "  This is normal for newly created clusters or short-running tasks"
          fi
          echo ""
          
          # Memory Utilization with error handling
          echo "üíæ Memory Utilization (%):"
          MEMORY_STATS=$(aws cloudwatch get-metric-statistics \
            --namespace AWS/ECS \
            --metric-name MemoryUtilization \
            --dimensions Name=ClusterName,Value="$CLUSTER_NAME" \
            --start-time "$START_TIME" \
            --end-time "$END_TIME" \
            --period 300 \
            --statistics Average,Maximum,Minimum \
            --query 'Datapoints[*].[Timestamp,Average,Maximum,Minimum]' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$MEMORY_STATS" ] && [ "$MEMORY_STATS" != "None" ]; then
            echo "$MEMORY_STATS" | sort | tail -10 | while read timestamp avg max min; do
              if [ -n "$timestamp" ] && [ "$timestamp" != "None" ]; then
                TIME_DISPLAY=$(${DATE_CMD} -d "$timestamp" '+%H:%M:%S' 2>/dev/null || echo "$timestamp")
                printf "  %s: Avg=%.1f%%, Max=%.1f%%, Min=%.1f%%\n" "$TIME_DISPLAY" "$avg" "$max" "$min"
              fi
            done
          else
            echo "  No memory metrics available for the specified time range"
            echo "  This is normal for newly created clusters or short-running tasks"
          fi
          echo ""
          
          # Service-level metrics
          echo "üîß SERVICE METRICS"
          echo "=================="
          
          # Running tasks count
          echo "üìä Active Tasks:"
          RUNNING_TASKS=$(aws cloudwatch get-metric-statistics \
            --namespace AWS/ECS \
            --metric-name RunningTasksCount \
            --dimensions Name=ClusterName,Value="$CLUSTER_NAME" \
            --start-time "$START_TIME" \
            --end-time "$END_TIME" \
            --period 300 \
            --statistics Average,Maximum \
            --query 'Datapoints[*].[Timestamp,Average,Maximum]' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$RUNNING_TASKS" ] && [ "$RUNNING_TASKS" != "None" ]; then
            echo "$RUNNING_TASKS" | sort | tail -5 | while read timestamp avg max; do
              if [ -n "$timestamp" ] && [ "$timestamp" != "None" ]; then
                TIME_DISPLAY=$(${DATE_CMD} -d "$timestamp" '+%H:%M:%S' 2>/dev/null || echo "$timestamp")
                printf "  %s: Avg=%.1f, Max=%.0f\n" "$TIME_DISPLAY" "$avg" "$max"
              fi
            done
          else
            echo "  No running tasks metrics available"
            echo "  This is normal for clusters with infrequent task execution"
          fi
          echo ""
          
          # Task-specific monitoring
          if [ -n "$TASK_ARNS" ] && [ "$TASK_ARNS" != "None" ]; then
            echo "üéØ INDIVIDUAL TASK PERFORMANCE"
            echo "=============================="
            
            for TASK_ARN in $TASK_ARNS; do
              if [ -n "$TASK_ARN" ] && [ "$TASK_ARN" != "None" ]; then
                TASK_ID=$(echo "$TASK_ARN" | rev | cut -d'/' -f1 | rev)
                echo "üìã Task: $TASK_ID"
                
                # Get task details with error handling
                TASK_DETAILS=$(aws ecs describe-tasks \
                  --cluster "$CLUSTER_NAME" \
                  --tasks "$TASK_ARN" \
                  --query 'tasks[0].[createdAt,startedAt,stoppedAt,lastStatus,containers[0].exitCode,stoppedReason]' \
                  --output text 2>/dev/null || echo "")
                
                if [ -n "$TASK_DETAILS" ] && [ "$TASK_DETAILS" != "None" ]; then
                  echo "$TASK_DETAILS" | while read created started stopped status exit_code reason; do
                    echo "  Created: $created"
                    echo "  Started: $started"
                    echo "  Stopped: $stopped"
                    echo "  Status: $status"
                    echo "  Exit Code: $exit_code"
                    [ "$reason" != "None" ] && echo "  Stop Reason: $reason"
                    
                    # Calculate duration if task completed
                    if [ "$started" != "None" ] && [ "$stopped" != "None" ]; then
                      START_EPOCH=$(${DATE_CMD} -d "$started" +%s 2>/dev/null || echo "")
                      STOP_EPOCH=$(${DATE_CMD} -d "$stopped" +%s 2>/dev/null || echo "")
                      if [ -n "$START_EPOCH" ] && [ -n "$STOP_EPOCH" ]; then
                        DURATION=$((STOP_EPOCH - START_EPOCH))
                        echo "  Duration: $((DURATION / 60)) minutes $((DURATION % 60)) seconds"
                      fi
                    fi
                  done
                else
                  echo "  No task details available"
                fi
                echo ""
              fi
            done
          else
            echo "üéØ No task ARNs available for detailed monitoring"
            echo ""
          fi
          
          # Cost estimation
          echo "üí∞ COST ESTIMATION"
          echo "=================="
          
          # Calculate Fargate costs based on CPU and memory usage
          CPU_VCPU=$(((${{ github.event.inputs.task_cpu }} + 1023) / 1024))
          MEMORY_GB=$(((${{ github.event.inputs.task_memory }} + 1023) / 1024))
          
          # Fargate pricing (approximate - varies by region)
          VCPU_COST_PER_HOUR=0.04048
          GB_COST_PER_HOUR=0.004445
          
          if [ -n "$SUCCESSFUL_MONTHS" ] && [ "$SUCCESSFUL_MONTHS" != "None" ]; then
            SUCCESSFUL_COUNT=$(echo $SUCCESSFUL_MONTHS | wc -w)
            if [ "${{ github.event.inputs.pipeline_mode }}" = "full" ]; then
              ESTIMATED_HOURS_PER_TASK=0.3  # 18 minutes average
            else
              ESTIMATED_HOURS_PER_TASK=0.05  # 3 minutes average
            fi
            
            # Use awk for floating point arithmetic instead of bc
            TOTAL_VCPU_HOURS=$(awk "BEGIN {print $SUCCESSFUL_COUNT * $CPU_VCPU * $ESTIMATED_HOURS_PER_TASK}")
            TOTAL_MEMORY_HOURS=$(awk "BEGIN {print $SUCCESSFUL_COUNT * $MEMORY_GB * $ESTIMATED_HOURS_PER_TASK}")
            
            VCPU_COST=$(awk "BEGIN {print $TOTAL_VCPU_HOURS * $VCPU_COST_PER_HOUR}")
            MEMORY_COST=$(awk "BEGIN {print $TOTAL_MEMORY_HOURS * $GB_COST_PER_HOUR}")
            TOTAL_COST=$(awk "BEGIN {print $VCPU_COST + $MEMORY_COST}")
            
            printf "üí∏ Estimated Fargate costs:\n"
            printf "  CPU: %.4f vCPU-hours √ó \$%.5f = \$%.4f\n" "$TOTAL_VCPU_HOURS" "$VCPU_COST_PER_HOUR" "$VCPU_COST"
            printf "  Memory: %.4f GB-hours √ó \$%.6f = \$%.4f\n" "$TOTAL_MEMORY_HOURS" "$GB_COST_PER_HOUR" "$MEMORY_COST"
            printf "  Total: \$%.4f\n" "$TOTAL_COST"
          else
            echo "  No successful tasks to calculate costs"
          fi
          echo ""
          
          # Summary
          echo "üìã MONITORING SUMMARY"
          echo "===================="
          echo "Monitoring period: $START_TIME to $END_TIME"
          echo "Cluster: $CLUSTER_NAME"
          echo "Task Definition: $TASK_DEFINITION"
          echo "Resource allocation: ${{ github.event.inputs.task_cpu }} CPU units, ${{ github.event.inputs.task_memory }} MiB memory"
          
          if [ -n "$SUCCESSFUL_MONTHS" ] && [ "$SUCCESSFUL_MONTHS" != "None" ]; then
            echo "‚úÖ Successfully processed: $(echo $SUCCESSFUL_MONTHS | wc -w) months"
          fi
          
          if [ -n "$FAILED_MONTHS" ] && [ "$FAILED_MONTHS" != "None" ]; then
            echo "‚ùå Failed to process: $(echo $FAILED_MONTHS | wc -w) months"
            echo "üìä For detailed task logs, check CloudWatch Logs:"
            echo "   https://console.aws.amazon.com/cloudwatch/home?region=${{ env.AWS_REGION }}#logsV2:log-groups/log-group/%2Fecs%2F${{ env.PROJECT_NAME }}"
          fi
          
          echo ""
          echo "üîó Additional monitoring resources:"
          echo "  - ECS Console: https://console.aws.amazon.com/ecs/home?region=${{ env.AWS_REGION }}#/clusters/$CLUSTER_NAME"
          echo "  - CloudWatch Metrics: https://console.aws.amazon.com/cloudwatch/home?region=${{ env.AWS_REGION }}#metricsV2:graph=~();namespace=AWS/ECS"
name: Manual Glicko Pipeline Run

on:
  workflow_dispatch:
    inputs:
      first_month:
        description: 'First month to process (YYYY-MM format)'
        required: true
        default: '2025-07'
      last_month:
        description: 'Last month to process (YYYY-MM format)'
        required: true
        default: '2025-07'
      task_cpu:
        description: 'CPU units (1024 = 1 vCPU)'
        required: false
        default: '1024'
      task_memory:
        description: 'Memory in MiB'
        required: false
        default: '2048'
      pipeline_mode:
        description: 'Pipeline mode to run'
        required: false
        default: 'full'
        type: choice
        options:
        - 'full'
        - 'post_scraping'

env:
  AWS_REGION: ${{ secrets.AWS_REGION }}
  PROJECT_NAME: chess-glicko

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Validate Month Format
      run: |
        if [[ ! "${{ github.event.inputs.first_month }}" =~ ^[0-9]{4}-[0-9]{2}$ ]]; then
          echo "Error: First month must be in YYYY-MM format"
          exit 1
        fi
        if [[ ! "${{ github.event.inputs.last_month }}" =~ ^[0-9]{4}-[0-9]{2}$ ]]; then
          echo "Error: Last month must be in YYYY-MM format"
          exit 1
        fi
        
        # Validate that first_month <= last_month
        if [[ "${{ github.event.inputs.first_month }}" > "${{ github.event.inputs.last_month }}" ]]; then
          echo "Error: First month must be less than or equal to last month"
          exit 1
        fi

    - name: Generate Month Range
      id: months
      run: |
        echo "=== Generating Month Range ==="
        
        # Parse input dates
        FIRST_MONTH="${{ github.event.inputs.first_month }}"
        LAST_MONTH="${{ github.event.inputs.last_month }}"
        
        echo "Processing from $FIRST_MONTH to $LAST_MONTH"
        
        # Convert dates to comparable format (YYYYMM)
        FIRST_NUMERIC=$(echo $FIRST_MONTH | tr -d '-')
        LAST_NUMERIC=$(echo $LAST_MONTH | tr -d '-')
        
        # Generate list of months
        MONTHS=""
        CURRENT_MONTH="$FIRST_MONTH"
        CURRENT_NUMERIC="$FIRST_NUMERIC"
        
        while [[ $CURRENT_NUMERIC -le $LAST_NUMERIC ]]; do
          if [[ -n "$MONTHS" ]]; then
            MONTHS="$MONTHS $CURRENT_MONTH"
          else
            MONTHS="$CURRENT_MONTH"
          fi
          
          # Break if we've reached the last month
          if [[ "$CURRENT_MONTH" == "$LAST_MONTH" ]]; then
            break
          fi
          
          # Calculate next month
          YEAR=$(echo $CURRENT_MONTH | cut -d'-' -f1)
          MONTH=$(echo $CURRENT_MONTH | cut -d'-' -f2)
          
          # Increment month
          MONTH=$((10#$MONTH + 1))
          
          # Handle year rollover
          if [[ $MONTH -gt 12 ]]; then
            MONTH=1
            YEAR=$((YEAR + 1))
          fi
          
          # Format next month
          CURRENT_MONTH=$(printf "%04d-%02d" $YEAR $MONTH)
          CURRENT_NUMERIC=$(echo $CURRENT_MONTH | tr -d '-')
        done
        
        echo "months=$MONTHS" >> $GITHUB_OUTPUT
        echo "Months to process: $MONTHS"
        
        # Count months for logging
        MONTH_COUNT=$(echo $MONTHS | wc -w)
        echo "month_count=$MONTH_COUNT" >> $GITHUB_OUTPUT
        echo "Total months to process: $MONTH_COUNT"

    - name: Get Infrastructure Details
      id: infra
      run: |
        echo "=== Getting Infrastructure Details ==="
        
        # Get cluster name
        CLUSTER_NAME=$(aws ecs list-clusters \
          --query "clusterArns[?contains(@, '${{ env.PROJECT_NAME }}')]" \
          --output text | cut -d'/' -f2)
        
        if [ -z "$CLUSTER_NAME" ]; then
          echo "‚ö†Ô∏è  No cluster found with project name, using default: chess-glicko-cluster"
          CLUSTER_NAME="chess-glicko-cluster"
        fi
        echo "cluster_name=$CLUSTER_NAME" >> $GITHUB_OUTPUT
        echo "Using cluster: $CLUSTER_NAME"
        
        # Get task definition
        TASK_DEF=$(aws ecs list-task-definitions \
          --family-prefix ${{ env.PROJECT_NAME }} \
          --sort DESC \
          --max-items 1 \
          --query 'taskDefinitionArns[0]' \
          --output text | cut -d'/' -f2 | cut -d':' -f1)
        
        if [ -z "$TASK_DEF" ] || [ "$TASK_DEF" = "None" ]; then
          echo "‚ö†Ô∏è  No task definition found with project name, using default: chess-glicko-task"
          TASK_DEF="chess-glicko-task"
        fi
        echo "task_definition=$TASK_DEF" >> $GITHUB_OUTPUT
        echo "Using task definition: $TASK_DEF"
        
        # Get S3 bucket name
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        S3_BUCKET_NAME="${{ env.PROJECT_NAME }}-data-$ACCOUNT_ID"
        echo "s3_bucket_name=$S3_BUCKET_NAME" >> $GITHUB_OUTPUT
        echo "Using S3 bucket: $S3_BUCKET_NAME"
        
        # Get network configuration - multiple subnets for better availability
        SUBNET_IDS=$(aws ec2 describe-subnets \
          --filters "Name=vpc-id,Values=$(aws ec2 describe-vpcs --filters 'Name=isDefault,Values=true' --query 'Vpcs[0].VpcId' --output text)" \
          --query 'Subnets[0:3].SubnetId' \
          --output text | tr '\t' ',')
        echo "subnet_ids=$SUBNET_IDS" >> $GITHUB_OUTPUT
        echo "Using subnets: $SUBNET_IDS"
        
        # Get security group
        SG_ID=$(aws ec2 describe-security-groups \
          --filters "Name=group-name,Values=chess-glicko-ecs-tasks" \
          --query 'SecurityGroups[0].GroupId' \
          --output text 2>/dev/null || echo "")
        
        if [ -z "$SG_ID" ] || [ "$SG_ID" = "None" ]; then
          SG_ID=$(aws ec2 describe-security-groups \
            --filters "Name=group-name,Values=default" \
            --query 'SecurityGroups[0].GroupId' \
            --output text)
          echo "‚ö†Ô∏è  Using default security group: $SG_ID"
        else
          echo "Using project security group: $SG_ID"
        fi
        echo "security_group_id=$SG_ID" >> $GITHUB_OUTPUT

    - name: Run Pipeline for Each Month
      id: pipeline_run
      env:
        CLUSTER_NAME: ${{ steps.infra.outputs.cluster_name }}
        TASK_DEFINITION: ${{ steps.infra.outputs.task_definition }}
        S3_BUCKET_NAME: ${{ steps.infra.outputs.s3_bucket_name }}
        SUBNET_IDS: ${{ steps.infra.outputs.subnet_ids }}
        SECURITY_GROUP_ID: ${{ steps.infra.outputs.security_group_id }}
        MONTHS: ${{ steps.months.outputs.months }}
        MONTH_COUNT: ${{ steps.months.outputs.month_count }}
      run: |
        echo "=== Running ${{ github.event.inputs.pipeline_mode }} Pipeline for Multiple Months ==="
        echo "Date range: ${{ github.event.inputs.first_month }} to ${{ github.event.inputs.last_month }}"
        echo "Total months: $MONTH_COUNT"
        echo "Mode: ${{ github.event.inputs.pipeline_mode }}"
        echo "CPU: ${{ github.event.inputs.task_cpu }}"
        echo "Memory: ${{ github.event.inputs.task_memory }}"
        echo "Cluster: $CLUSTER_NAME"
        echo "Task Definition: $TASK_DEFINITION"
        echo "S3 Bucket: $S3_BUCKET_NAME"
        echo "Subnets: $SUBNET_IDS"
        echo "Security Group: $SECURITY_GROUP_ID"
        echo ""
        
        # Store pipeline start time for monitoring
        PIPELINE_START_TIME=$(date -u +%Y-%m-%dT%H:%M:%S)
        echo "pipeline_start_time=$PIPELINE_START_TIME" >> $GITHUB_OUTPUT
        
        # Prepare pipeline mode description
        if [ "${{ github.event.inputs.pipeline_mode }}" = "full" ]; then
          echo "üìä Full pipeline will run all steps for each month:"
          echo "  - Download data archives"
          echo "  - Extract and process games"
          echo "  - Calculate Glicko ratings"
          echo "  - Upload results to S3"
          ESTIMATED_TIME_PER_MONTH=17
          echo "  ‚ö†Ô∏è  Expected duration per month: 15-20 minutes"
        else
          echo "üìä Post-scraping pipeline will run for each month:"
          echo "  - Process calculation data"
          echo "  - Calculate Glicko ratings"
          echo "  - Upload results to S3"
          ESTIMATED_TIME_PER_MONTH=3
          echo "  ‚ö†Ô∏è  Expected duration per month: 2-5 minutes"
        fi
        
        TOTAL_ESTIMATED_TIME=$((ESTIMATED_TIME_PER_MONTH * MONTH_COUNT))
        echo "  üïê Total estimated time: ~$TOTAL_ESTIMATED_TIME minutes"
        echo ""
        
        # Track results
        SUCCESSFUL_MONTHS=""
        FAILED_MONTHS=""
        CURRENT_MONTH_NUM=1
        ALL_TASK_ARNS=""
        
        # Process each month
        for MONTH in $MONTHS; do
          echo "=================================="
          echo "üóìÔ∏è  Processing month $CURRENT_MONTH_NUM of $MONTH_COUNT: $MONTH"
          echo "=================================="
          
          # Run the task
          echo "Starting pipeline task for $MONTH..."
          TASK_ARN=$(aws ecs run-task \
            --cluster $CLUSTER_NAME \
            --task-definition $TASK_DEFINITION \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_IDS],assignPublicIp=ENABLED,securityGroups=[$SECURITY_GROUP_ID]}" \
            --overrides "{
              \"taskRoleArn\": \"$(aws ecs describe-task-definition --task-definition $TASK_DEFINITION --query 'taskDefinition.taskRoleArn' --output text)\",
              \"cpu\": \"${{ github.event.inputs.task_cpu }}\",
              \"memory\": \"${{ github.event.inputs.task_memory }}\",
              \"containerOverrides\": [{
                \"name\": \"chess-glicko\",
                \"environment\": [{
                  \"name\": \"PROCESS_MONTH\",
                  \"value\": \"$MONTH\"
                }, {
                  \"name\": \"PIPELINE_MODE\",
                  \"value\": \"${{ github.event.inputs.pipeline_mode }}\"
                }, {
                  \"name\": \"S3_BUCKET\",
                  \"value\": \"$S3_BUCKET_NAME\"
                }]
              }]
            }" \
            --query 'tasks[0].taskArn' \
            --output text)
          
          if [ -n "$TASK_ARN" ] && [ "$TASK_ARN" != "None" ]; then
            echo "‚úÖ Pipeline task started successfully for $MONTH!"
            echo "Task ARN: $TASK_ARN"
            
            # Store task ARN for monitoring
            ALL_TASK_ARNS="$ALL_TASK_ARNS $TASK_ARN"
            
            # Wait for task to complete - increased to 1 hour (3600 seconds)
            echo "‚è≥ Waiting for task to complete..."
            TASK_STATUS="RUNNING"
            MAX_WAIT_TIME=3600  # 1 hour max wait
            WAIT_TIME=0
            
            while [[ "$TASK_STATUS" != "STOPPED" && $WAIT_TIME -lt $MAX_WAIT_TIME ]]; do
              sleep 30
              WAIT_TIME=$((WAIT_TIME + 30))
              TASK_STATUS=$(aws ecs describe-tasks \
                --cluster "$CLUSTER_NAME" \
                --tasks "$TASK_ARN" \
                --query 'tasks[0].lastStatus' \
                --output text 2>/dev/null || echo "UNKNOWN")
              
              if [[ $((WAIT_TIME % 300)) -eq 0 ]]; then  # Log every 5 minutes
                echo "‚è≥ Task still running after $((WAIT_TIME / 60)) minutes... (Status: $TASK_STATUS)"
              fi
            done
            
            # Check final status
            if [[ "$TASK_STATUS" = "STOPPED" ]]; then
              EXIT_CODE=$(aws ecs describe-tasks \
                --cluster "$CLUSTER_NAME" \
                --tasks "$TASK_ARN" \
                --query 'tasks[0].containers[0].exitCode' \
                --output text 2>/dev/null || echo "unknown")
              
              if [[ "$EXIT_CODE" = "0" ]]; then
                echo "‚úÖ Task completed successfully for $MONTH!"
                SUCCESSFUL_MONTHS="$SUCCESSFUL_MONTHS $MONTH"
              else
                echo "‚ùå Task failed for $MONTH (Exit code: $EXIT_CODE)"
                STOP_REASON=$(aws ecs describe-tasks \
                  --cluster "$CLUSTER_NAME" \
                  --tasks "$TASK_ARN" \
                  --query 'tasks[0].stoppedReason' \
                  --output text 2>/dev/null || echo "unknown")
                echo "Stop reason: $STOP_REASON"
                FAILED_MONTHS="$FAILED_MONTHS $MONTH"
              fi
            else
              echo "‚ùå Task timed out for $MONTH (waited $((WAIT_TIME / 60)) minutes)"
              FAILED_MONTHS="$FAILED_MONTHS $MONTH"
            fi
          else
            echo "‚ùå Failed to start pipeline task for $MONTH"
            echo "Task ARN: '$TASK_ARN'"
            FAILED_MONTHS="$FAILED_MONTHS $MONTH"
          fi
          
          CURRENT_MONTH_NUM=$((CURRENT_MONTH_NUM + 1))
          echo ""
        done
        
        # Store results for monitoring
        echo "task_arns=$ALL_TASK_ARNS" >> $GITHUB_OUTPUT
        echo "successful_months=$SUCCESSFUL_MONTHS" >> $GITHUB_OUTPUT
        echo "failed_months=$FAILED_MONTHS" >> $GITHUB_OUTPUT
        
        echo "=================================="
        echo "üìä FINAL RESULTS"
        echo "=================================="
        echo "Total months processed: $MONTH_COUNT"
        
        if [[ -n "$SUCCESSFUL_MONTHS" ]]; then
          SUCCESSFUL_COUNT=$(echo $SUCCESSFUL_MONTHS | wc -w)
          echo "‚úÖ Successful months ($SUCCESSFUL_COUNT):$SUCCESSFUL_MONTHS"
        fi
        
        if [[ -n "$FAILED_MONTHS" ]]; then
          FAILED_COUNT=$(echo $FAILED_MONTHS | wc -w)
          echo "‚ùå Failed months ($FAILED_COUNT):$FAILED_MONTHS"
          echo ""
          echo "üîó Check logs for failed months:"
          echo "  - CloudWatch Logs: https://console.aws.amazon.com/cloudwatch/home?region=${{ env.AWS_REGION }}#logsV2:log-groups/log-group/%2Fecs%2F${{ env.PROJECT_NAME }}"
          exit 1
        else
          echo "üéâ All months processed successfully!"
        fi

    - name: Monitor Resource Usage and Performance
      if: always()
      env:
        CLUSTER_NAME: ${{ steps.infra.outputs.cluster_name }}
        TASK_DEFINITION: ${{ steps.infra.outputs.task_definition }}
        PIPELINE_START_TIME: ${{ steps.pipeline_run.outputs.pipeline_start_time }}
        TASK_ARNS: ${{ steps.pipeline_run.outputs.task_arns }}
        SUCCESSFUL_MONTHS: ${{ steps.pipeline_run.outputs.successful_months }}
        FAILED_MONTHS: ${{ steps.pipeline_run.outputs.failed_months }}
      run: |
        echo "=== Resource Usage and Performance Monitoring ==="
        echo "Pipeline run period: $PIPELINE_START_TIME to $(date -u +%Y-%m-%dT%H:%M:%S)"
        echo ""
        
        # Calculate monitoring time window (add 10 minutes buffer)
        START_TIME=$(date -u -d "@$(($(date -u -d "$PIPELINE_START_TIME" +%s) - 600))" +%Y-%m-%dT%H:%M:%S)
        END_TIME=$(date -u +%Y-%m-%dT%H:%M:%S)
        
        echo "üìä Monitoring time window: $START_TIME to $END_TIME"
        echo ""
        
        # Monitor cluster-level metrics
        echo "üñ•Ô∏è  CLUSTER METRICS"
        echo "==================="
        
        # CPU Utilization
        echo "üìà CPU Utilization (%):"
        CPU_STATS=$(aws cloudwatch get-metric-statistics \
          --namespace AWS/ECS \
          --metric-name CPUUtilization \
          --dimensions Name=ClusterName,Value=$CLUSTER_NAME \
          --start-time "$START_TIME" \
          --end-time "$END_TIME" \
          --period 300 \
          --statistics Average,Maximum,Minimum \
          --query 'Datapoints[*].[Timestamp,Average,Maximum,Minimum]' \
          --output text 2>/dev/null)
        
        if [ -n "$CPU_STATS" ]; then
          echo "$CPU_STATS" | sort | tail -10 | while read timestamp avg max min; do
            printf "  %s: Avg=%.1f%%, Max=%.1f%%, Min=%.1f%%\n" "$(date -d "$timestamp" '+%H:%M:%S')" "$avg" "$max" "$min"
          done
        else
          echo "  No CPU metrics available for the specified time range"
        fi
        echo ""
        
        # Memory Utilization
        echo "üíæ Memory Utilization (%):"
        MEMORY_STATS=$(aws cloudwatch get-metric-statistics \
          --namespace AWS/ECS \
          --metric-name MemoryUtilization \
          --dimensions Name=ClusterName,Value=$CLUSTER_NAME \
          --start-time "$START_TIME" \
          --end-time "$END_TIME" \
          --period 300 \
          --statistics Average,Maximum,Minimum \
          --query 'Datapoints[*].[Timestamp,Average,Maximum,Minimum]' \
          --output text 2>/dev/null)
        
        if [ -n "$MEMORY_STATS" ]; then
          echo "$MEMORY_STATS" | sort | tail -10 | while read timestamp avg max min; do
            printf "  %s: Avg=%.1f%%, Max=%.1f%%, Min=%.1f%%\n" "$(date -d "$timestamp" '+%H:%M:%S')" "$avg" "$max" "$min"
          done
        else
          echo "  No memory metrics available for the specified time range"
        fi
        echo ""
        
        # Service-level metrics
        echo "üîß SERVICE METRICS"
        echo "=================="
        
        # Running tasks count
        echo "üìä Active Tasks:"
        RUNNING_TASKS=$(aws cloudwatch get-metric-statistics \
          --namespace AWS/ECS \
          --metric-name RunningTasksCount \
          --dimensions Name=ClusterName,Value=$CLUSTER_NAME \
          --start-time "$START_TIME" \
          --end-time "$END_TIME" \
          --period 300 \
          --statistics Average,Maximum \
          --query 'Datapoints[*].[Timestamp,Average,Maximum]' \
          --output text 2>/dev/null)
        
        if [ -n "$RUNNING_TASKS" ]; then
          echo "$RUNNING_TASKS" | sort | tail -5 | while read timestamp avg max; do
            printf "  %s: Avg=%.1f, Max=%.0f\n" "$(date -d "$timestamp" '+%H:%M:%S')" "$avg" "$max"
          done
        else
          echo "  No running tasks metrics available"
        fi
        echo ""
        
        # Task-specific monitoring
        if [ -n "$TASK_ARNS" ]; then
          echo "üéØ INDIVIDUAL TASK PERFORMANCE"
          echo "=============================="
          
          for TASK_ARN in $TASK_ARNS; do
            if [ -n "$TASK_ARN" ] && [ "$TASK_ARN" != "None" ]; then
              TASK_ID=$(echo "$TASK_ARN" | cut -d'/' -f3)
              echo "üìã Task: $TASK_ID"
              
              # Get task details
              TASK_DETAILS=$(aws ecs describe-tasks \
                --cluster "$CLUSTER_NAME" \
                --tasks "$TASK_ARN" \
                --query 'tasks[0].[createdAt,startedAt,stoppedAt,lastStatus,containers[0].exitCode,stoppedReason]' \
                --output text 2>/dev/null)
              
              if [ -n "$TASK_DETAILS" ]; then
                echo "$TASK_DETAILS" | while read created started stopped status exit_code reason; do
                  echo "  Created: $created"
                  echo "  Started: $started"
                  echo "  Stopped: $stopped"
                  echo "  Status: $status"
                  echo "  Exit Code: $exit_code"
                  [ "$reason" != "None" ] && echo "  Stop Reason: $reason"
                  
                  # Calculate duration if task completed
                  if [ "$started" != "None" ] && [ "$stopped" != "None" ]; then
                    DURATION=$(( $(date -d "$stopped" +%s) - $(date -d "$started" +%s) ))
                    echo "  Duration: $((DURATION / 60)) minutes $((DURATION % 60)) seconds"
                  fi
                done
              fi
              echo ""
            fi
          done
        fi
        
        # Cost estimation
        echo "üí∞ COST ESTIMATION"
        echo "=================="
        
        # Calculate Fargate costs based on CPU and memory usage
        CPU_VCPU=$(((${{ github.event.inputs.task_cpu }} + 1023) / 1024))
        MEMORY_GB=$(((${{ github.event.inputs.task_memory }} + 1023) / 1024))
        
        # Fargate pricing (approximate - varies by region)
        VCPU_COST_PER_HOUR=0.04048
        GB_COST_PER_HOUR=0.004445
        
        if [ -n "$SUCCESSFUL_MONTHS" ]; then
          SUCCESSFUL_COUNT=$(echo $SUCCESSFUL_MONTHS | wc -w)
          if [ "${{ github.event.inputs.pipeline_mode }}" = "full" ]; then
            ESTIMATED_HOURS_PER_TASK=0.3  # 18 minutes average
          else
            ESTIMATED_HOURS_PER_TASK=0.05  # 3 minutes average
          fi
          
          TOTAL_VCPU_HOURS=$(echo "$SUCCESSFUL_COUNT * $CPU_VCPU * $ESTIMATED_HOURS_PER_TASK" | bc -l)
          TOTAL_MEMORY_HOURS=$(echo "$SUCCESSFUL_COUNT * $MEMORY_GB * $ESTIMATED_HOURS_PER_TASK" | bc -l)
          
          VCPU_COST=$(echo "$TOTAL_VCPU_HOURS * $VCPU_COST_PER_HOUR" | bc -l)
          MEMORY_COST=$(echo "$TOTAL_MEMORY_HOURS * $GB_COST_PER_HOUR" | bc -l)
          TOTAL_COST=$(echo "$VCPU_COST + $MEMORY_COST" | bc -l)
          
          printf "üí∏ Estimated Fargate costs:\n"
          printf "  CPU: %.4f vCPU-hours √ó \$%.5f = \$%.4f\n" "$TOTAL_VCPU_HOURS" "$VCPU_COST_PER_HOUR" "$VCPU_COST"
          printf "  Memory: %.4f GB-hours √ó \$%.6f = \$%.4f\n" "$TOTAL_MEMORY_HOURS" "$GB_COST_PER_HOUR" "$MEMORY_COST"
          printf "  Total: \$%.4f\n" "$TOTAL_COST"
        else
          echo "  No successful tasks to calculate costs"
        fi
        echo ""
        
        # Summary
        echo "üìã MONITORING SUMMARY"
        echo "===================="
        echo "Monitoring period: $(date -d "$START_TIME" '+%Y-%m-%d %H:%M:%S') to $(date -d "$END_TIME" '+%Y-%m-%d %H:%M:%S')"
        echo "Cluster: $CLUSTER_NAME"
        echo "Task Definition: $TASK_DEFINITION"
        echo "Resource allocation: ${{ github.event.inputs.task_cpu }} CPU units, ${{ github.event.inputs.task_memory }} MiB memory"
        
        if [ -n "$SUCCESSFUL_MONTHS" ]; then
          echo "‚úÖ Successfully processed: $(echo $SUCCESSFUL_MONTHS | wc -w) months"
        fi
        
        if [ -n "$FAILED_MONTHS" ]; then
          echo "‚ùå Failed to process: $(echo $FAILED_MONTHS | wc -w) months"
          echo "üìä For detailed task logs, check CloudWatch Logs:"
          echo "   https://console.aws.amazon.com/cloudwatch/home?region=${{ env.AWS_REGION }}#logsV2:log-groups/log-group/%2Fecs%2F${{ env.PROJECT_NAME }}"
        fi
        
        echo ""
        echo "üîó Additional monitoring resources:"
        echo "  - ECS Console: https://console.aws.amazon.com/ecs/home?region=${{ env.AWS_REGION }}#/clusters/$CLUSTER_NAME"
        echo "  - CloudWatch Metrics: https://console.aws.amazon.com/cloudwatch/home?region=${{ env.AWS_REGION }}#metricsV2:graph=~();namespace=AWS/ECS"
name: Deploy Chess Glicko Pipeline

on:
  push:
    branches: [ main, master ]
    paths:
      - 'src/**'
      - 'rust-src/**'
      - 'terraform/**'
      - 'Dockerfile'
      - 'requirements.txt'
      - 'entrypoint.sh'
  workflow_dispatch:
    inputs:
      force_deploy:
        description: 'Force deployment even if no changes'
        required: false
        default: 'false'
      test_type:
        description: 'Type of test to run'
        required: false
        default: 'none'
        type: choice
        options:
        - 'none'
        - 'full'
        - 'post_scraping'
      test_month:
        description: 'Month to test (YYYY-MM format, defaults to previous month)'
        required: false
        default: ''

env:
  AWS_REGION: ${{ secrets.AWS_REGION }}
  PROJECT_NAME: chess-glicko

jobs:
  deploy-infrastructure:
    runs-on: ubuntu-latest
    outputs:
      ecr_repository_name: ${{ steps.terraform-outputs.outputs.ecr_repository_name }}
      ecs_cluster_name: ${{ steps.terraform-outputs.outputs.ecs_cluster_name }}
      task_definition_family: ${{ steps.terraform-outputs.outputs.task_definition_family }}
      s3_bucket_name: ${{ steps.terraform-outputs.outputs.s3_bucket_name }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
        terraform_wrapper: false

    - name: Terraform Init
      working-directory: ./terraform
      run: terraform init

    - name: Import Existing Resources
      working-directory: ./terraform
      run: |
        echo "Checking for existing resources to import..."

        # Get AWS Account ID for consistent bucket naming
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        S3_BUCKET_NAME="${{ env.PROJECT_NAME }}-data-$ACCOUNT_ID"
        
        # Import S3 bucket if it exists
        if aws s3api head-bucket --bucket "$S3_BUCKET_NAME" 2>/dev/null; then
          echo "S3 bucket exists, importing..."
          terraform import aws_s3_bucket.chess_data "$S3_BUCKET_NAME" || true
        else
          echo "S3 bucket does not exist, will be created"
        fi
        
        # Import ECR repository if it exists
        if aws ecr describe-repositories --repository-names chess-glicko-pipeline --region ${{ env.AWS_REGION }} 2>/dev/null; then
          echo "ECR repository exists, importing..."
          terraform import aws_ecr_repository.chess_pipeline chess-glicko-pipeline || true
        fi
        
        # Import CloudWatch log group if it exists
        if aws logs describe-log-groups --log-group-name-prefix /ecs/chess-glicko --region ${{ env.AWS_REGION }} --query 'logGroups[0]' --output text 2>/dev/null | grep -q "/ecs/chess-glicko"; then
          echo "CloudWatch log group exists, importing..."
          terraform import aws_cloudwatch_log_group.chess_pipeline /ecs/chess-glicko || true
        fi
        
        # Import IAM roles if they exist
        if aws iam get-role --role-name chess-glicko-ecs-execution-role 2>/dev/null; then
          echo "ECS execution role exists, importing..."
          terraform import aws_iam_role.ecs_execution_role chess-glicko-ecs-execution-role || true
        fi
        
        if aws iam get-role --role-name chess-glicko-ecs-task-role 2>/dev/null; then
          echo "ECS task role exists, importing..."
          terraform import aws_iam_role.ecs_task_role chess-glicko-ecs-task-role || true
        fi
        
        if aws iam get-role --role-name chess-glicko-eventbridge-role 2>/dev/null; then
          echo "EventBridge role exists, importing..."
          terraform import aws_iam_role.eventbridge_role chess-glicko-eventbridge-role || true
        fi
        
        # Import security group if it exists
        SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=chess-glicko-ecs-tasks" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null)
        if [ "$SG_ID" != "None" ] && [ -n "$SG_ID" ]; then
          echo "Security group exists, importing..."
          terraform import aws_security_group.ecs_tasks $SG_ID || true
        fi

    - name: Create Terraform Variables
      working-directory: ./terraform
      run: |
        cat > terraform.tfvars <<EOF
        aws_region = "${{ env.AWS_REGION }}"
        project_name = "${{ env.PROJECT_NAME }}"
        notification_email = "${{ secrets.NOTIFICATION_EMAIL }}"
        EOF

    - name: Terraform Plan
      working-directory: ./terraform
      run: terraform plan -out=tfplan

    - name: Terraform Apply
      working-directory: ./terraform
      run: terraform apply -auto-approve tfplan

    - name: Get Terraform Outputs
      id: terraform-outputs
      working-directory: ./terraform
      run: |
        echo "=== Debugging Terraform Outputs ==="
        terraform output
        echo "=== Setting GitHub Outputs ==="
        
        # Get outputs and verify they exist
        ECR_URL=$(terraform output -raw ecr_repository_url 2>/dev/null || echo "")
        CLUSTER_NAME=$(terraform output -raw ecs_cluster_name 2>/dev/null || echo "")
        TASK_ARN=$(terraform output -raw task_definition_arn 2>/dev/null || echo "")
        S3_BUCKET=$(terraform output -raw s3_bucket_name 2>/dev/null || echo "")
        
        # Debug the values
        echo "ECR_URL: '$ECR_URL'"
        echo "CLUSTER_NAME: '$CLUSTER_NAME'"
        echo "TASK_ARN: '$TASK_ARN'"
        echo "S3_BUCKET: '$S3_BUCKET'"
        
        # Extract components that don't contain secrets
        if [ -n "$ECR_URL" ]; then
          # Extract registry and repository name separately
          ECR_REPO_NAME=$(echo "$ECR_URL" | cut -d'/' -f2)
          
          echo "ECR_REPO_NAME: '$ECR_REPO_NAME'"
          
          # Set sanitized outputs (repository name doesn't contain account ID)
          echo "ecr_repository_name=$ECR_REPO_NAME" >> $GITHUB_OUTPUT
          echo "✅ Set ECR outputs"
        else
          echo "ERROR: ecr_repository_url is empty"
          exit 1
        fi
        
        if [ -n "$CLUSTER_NAME" ]; then
          echo "ecs_cluster_name=$CLUSTER_NAME" >> $GITHUB_OUTPUT
          echo "✅ Set ecs_cluster_name output"
        else
          echo "ERROR: ecs_cluster_name is empty"
          exit 1
        fi
        
        if [ -n "$TASK_ARN" ]; then
          # Extract just the task family name (doesn't contain account ID)
          TASK_FAMILY=$(echo "$TASK_ARN" | cut -d'/' -f2 | cut -d':' -f1)
          echo "TASK_FAMILY: '$TASK_FAMILY'"
          echo "task_definition_family=$TASK_FAMILY" >> $GITHUB_OUTPUT
          echo "✅ Set task_definition_family output"
        else
          echo "ERROR: task_definition_arn is empty"
          exit 1
        fi
        
        if [ -n "$S3_BUCKET" ]; then
          echo "s3_bucket_name=$S3_BUCKET" >> $GITHUB_OUTPUT
          echo "✅ Set s3_bucket_name output"
        else
          echo "ERROR: s3_bucket_name is empty"
          exit 1
        fi
        
        # Final verification - show what was written to GITHUB_OUTPUT
        echo "=== Final GITHUB_OUTPUT verification ==="
        echo "GITHUB_OUTPUT file contents:"
        cat $GITHUB_OUTPUT || echo "Could not read GITHUB_OUTPUT file"

  build-and-deploy:
    needs: deploy-infrastructure
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Debug Job Dependencies
      run: |
        echo "=== Debugging Job Dependencies ==="
        echo "ECR Repository Name: '${{ needs.deploy-infrastructure.outputs.ecr_repository_name }}'"
        echo "ECR Registry: '${{ needs.deploy-infrastructure.outputs.ecr_registry }}'"
        echo "ECS Cluster Name: '${{ needs.deploy-infrastructure.outputs.ecs_cluster_name }}'"
        echo "Task Definition Family: '${{ needs.deploy-infrastructure.outputs.task_definition_family }}'"
        echo "S3 Bucket Name: '${{ needs.deploy-infrastructure.outputs.s3_bucket_name }}'"
        
        # Check if any outputs are empty
        if [ -z "${{ needs.deploy-infrastructure.outputs.ecr_repository_name }}" ]; then
          echo "❌ ERROR: ecr_repository_name is empty from previous job"
          echo "This indicates a problem with job output passing"
          exit 1
        else
          echo "✅ ecr_repository_name received successfully"
        fi
        
        if [ -z "${{ needs.deploy-infrastructure.outputs.ecs_cluster_name }}" ]; then
          echo "❌ ERROR: ecs_cluster_name is empty from previous job"
          exit 1
        else
          echo "✅ ecs_cluster_name received successfully"
        fi

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Build, tag, and push image to Amazon ECR
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        ECR_REPOSITORY_NAME: ${{ needs.deploy-infrastructure.outputs.ecr_repository_name }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        echo "=== Debug ECR Variables ==="
        echo "ECR_REGISTRY: '$ECR_REGISTRY'"
        echo "ECR_REPOSITORY_NAME: '$ECR_REPOSITORY_NAME'"
        echo "IMAGE_TAG: '$IMAGE_TAG'"
        
        # Check if ECR_REPOSITORY_NAME is empty
        if [ -z "$ECR_REPOSITORY_NAME" ]; then
          echo "⚠️  ECR_REPOSITORY_NAME is empty, trying to get it from AWS directly..."
          ECR_REPOSITORY_NAME=$(aws ecr describe-repositories \
            --repository-names chess-glicko-pipeline \
            --query 'repositories[0].repositoryName' \
            --output text 2>/dev/null || echo "chess-glicko-pipeline")
          
          echo "✅ Using ECR repository name: '$ECR_REPOSITORY_NAME'"
        fi
        
        # Validate we have what we need
        if [ -z "$ECR_REGISTRY" ] || [ -z "$ECR_REPOSITORY_NAME" ]; then
          echo "❌ ERROR: Missing required ECR variables"
          echo "ECR_REGISTRY: '$ECR_REGISTRY'"
          echo "ECR_REPOSITORY_NAME: '$ECR_REPOSITORY_NAME'"
          exit 1
        fi
        
        echo "=== Building Docker Images ==="
        # Build and tag
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY_NAME:latest .
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY_NAME:$IMAGE_TAG .
        
        echo "=== Pushing to ECR ==="
        # Push
        docker push $ECR_REGISTRY/$ECR_REPOSITORY_NAME:latest
        docker push $ECR_REGISTRY/$ECR_REPOSITORY_NAME:$IMAGE_TAG
        
        echo "=== Successfully pushed images ==="
        echo "  Latest: $ECR_REGISTRY/$ECR_REPOSITORY_NAME:latest"
        echo "  Tagged: $ECR_REGISTRY/$ECR_REPOSITORY_NAME:$IMAGE_TAG"

    - name: Update ECS Task Definition
      env:
        CLUSTER_NAME: ${{ needs.deploy-infrastructure.outputs.ecs_cluster_name }}
        ECR_REPOSITORY_NAME: ${{ needs.deploy-infrastructure.outputs.ecr_repository_name }}
        TASK_DEFINITION_FAMILY: ${{ needs.deploy-infrastructure.outputs.task_definition_family }}
      run: |
        echo "=== Debug Task Definition Update Variables ==="
        echo "CLUSTER_NAME: '$CLUSTER_NAME'"
        echo "ECR_REPOSITORY_NAME: '$ECR_REPOSITORY_NAME'"
        echo "TASK_DEFINITION_FAMILY: '$TASK_DEFINITION_FAMILY'"
        
        # Fallback for task definition family if needed
        if [ -z "$TASK_DEFINITION_FAMILY" ]; then
          echo "⚠️  TASK_DEFINITION_FAMILY is empty, using default: chess-glicko-task"
          TASK_DEFINITION_FAMILY="chess-glicko-task"
        fi
        
        # Fallback for repository name if needed
        if [ -z "$ECR_REPOSITORY_NAME" ]; then
          echo "⚠️  ECR_REPOSITORY_NAME is empty, using default: chess-glicko-pipeline"
          ECR_REPOSITORY_NAME="chess-glicko-pipeline"
        fi
        
        echo "Using task family: $TASK_DEFINITION_FAMILY"
        echo "Using repository name: $ECR_REPOSITORY_NAME"
        
        # Get the task definition
        aws ecs describe-task-definition \
          --task-definition $TASK_DEFINITION_FAMILY \
          --query taskDefinition > task-def.json
        
        # Build new image URI
        NEW_IMAGE="${{ steps.login-ecr.outputs.registry }}/$ECR_REPOSITORY_NAME:latest"
        echo "New image: $NEW_IMAGE"
        
        # Create new task definition
        jq --arg IMAGE "$NEW_IMAGE" \
          '.containerDefinitions[0].image = $IMAGE | del(.taskDefinitionArn) | del(.revision) | del(.status) | del(.requiresAttributes) | del(.placementConstraints) | del(.compatibilities) | del(.registeredAt) | del(.registeredBy)' \
          task-def.json > new-task-def.json
        
        # Register new task definition
        NEW_TASK_DEF=$(aws ecs register-task-definition \
          --cli-input-json file://new-task-def.json \
          --query 'taskDefinition.taskDefinitionArn' \
          --output text)
        
        echo "✅ Registered new task definition: $NEW_TASK_DEF"

  test-full-pipeline:
    needs: [deploy-infrastructure, build-and-deploy]
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'full'
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Run Full Pipeline Test
      env:
        CLUSTER_NAME: ${{ needs.deploy-infrastructure.outputs.ecs_cluster_name }}
        TASK_DEFINITION_FAMILY: ${{ needs.deploy-infrastructure.outputs.task_definition_family }}
        S3_BUCKET_NAME: ${{ needs.deploy-infrastructure.outputs.s3_bucket_name }}
      run: |
        echo "=== Running Full Pipeline Test (All Steps) ==="
        echo "CLUSTER_NAME: '$CLUSTER_NAME'"
        echo "TASK_DEFINITION_FAMILY: '$TASK_DEFINITION_FAMILY'"
        echo "S3_BUCKET_NAME: '$S3_BUCKET_NAME'"
        
        # Fallback for cluster name if needed
        if [ -z "$CLUSTER_NAME" ]; then
          echo "⚠️  CLUSTER_NAME is empty, using default: chess-glicko-cluster"
          CLUSTER_NAME="chess-glicko-cluster"
        fi
        
        # Fallback for task definition family if needed
        if [ -z "$TASK_DEFINITION_FAMILY" ]; then
          echo "⚠️  TASK_DEFINITION_FAMILY is empty, using default: chess-glicko-task"
          TASK_DEFINITION_FAMILY="chess-glicko-task"
        fi
        
        # Determine test month
        if [ -n "${{ github.event.inputs.test_month }}" ]; then
          TEST_MONTH="${{ github.event.inputs.test_month }}"
        else
          TEST_MONTH=$(date -d "$(date +'%Y-%m-01') -1 month" +'%Y-%m')
        fi
        
        echo "Testing full pipeline with month: $TEST_MONTH"
        
        # Get network configuration
        SUBNET_IDS=$(aws ec2 describe-subnets \
          --filters "Name=vpc-id,Values=$(aws ec2 describe-vpcs --filters 'Name=isDefault,Values=true' --query 'Vpcs[0].VpcId' --output text)" \
          --query 'Subnets[0:3].SubnetId' \
          --output text | tr '\t' ',')
        
        SG_ID=$(aws ec2 describe-security-groups \
          --filters "Name=group-name,Values=chess-glicko-ecs-tasks" \
          --query 'SecurityGroups[0].GroupId' \
          --output text 2>/dev/null || echo "")
        
        if [ -z "$SG_ID" ] || [ "$SG_ID" = "None" ]; then
          SG_ID=$(aws ec2 describe-security-groups \
            --filters "Name=group-name,Values=default" \
            --query 'SecurityGroups[0].GroupId' \
            --output text)
        fi
        
        echo "Using subnets: $SUBNET_IDS"
        echo "Using security group: $SG_ID"
        
        # Calculate test month (previous month)
        TEST_MONTH=$(date -d "$(date +'%Y-%m-01') -1 month" +'%Y-%m')
        echo "Testing with month: $TEST_MONTH"
        
        # Run legacy test task
        echo "Running legacy ECS task..."
        TASK_ARN=$(aws ecs run-task \
          --cluster "$CLUSTER_NAME" \
          --task-definition "$TASK_DEFINITION_FAMILY" \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_IDS],assignPublicIp=ENABLED,securityGroups=[$SG_ID]}" \
          --overrides "{\"containerOverrides\":[{\"name\":\"chess-glicko\",\"environment\":[{\"name\":\"PROCESS_MONTH\",\"value\":\"$TEST_MONTH\"}]}]}" \
          --query 'tasks[0].taskArn' \
          --output text)
        
        if [ -n "$TASK_ARN" ] && [ "$TASK_ARN" != "None" ]; then
          echo "✅ Legacy test task started: $TASK_ARN"
          echo "Monitor with: aws ecs describe-tasks --cluster $CLUSTER_NAME --tasks $TASK_ARN"
          
          # Wait a moment and check task status
          sleep 10
          TASK_STATUS=$(aws ecs describe-tasks \
            --cluster "$CLUSTER_NAME" \
            --tasks "$TASK_ARN" \
            --query 'tasks[0].lastStatus' \
            --output text)
          echo "Task status after 10 seconds: $TASK_STATUS"
        else
          echo "❌ Failed to start legacy test task"
          exit 1
        fi

        # Get network configuration
        SUBNET_IDS=$(aws ec2 describe-subnets \
          --filters "Name=vpc-id,Values=$(aws ec2 describe-vpcs --filters 'Name=isDefault,Values=true' --query 'Vpcs[0].VpcId' --output text)" \
          --query 'Subnets[0:3].SubnetId' \
          --output text | tr '\t' ',')
        
        SG_ID=$(aws ec2 describe-security-groups \
          --filters "Name=group-name,Values=chess-glicko-ecs-tasks" \
          --query 'SecurityGroups[0].GroupId' \
          --output text 2>/dev/null || echo "")
        
        if [ -z "$SG_ID" ] || [ "$SG_ID" = "None" ]; then
          SG_ID=$(aws ec2 describe-security-groups \
            --filters "Name=group-name,Values=default" \
            --query 'SecurityGroups[0].GroupId' \
            --output text)
        fi
        
        echo "Using subnets: $SUBNET_IDS"
        echo "Using security group: $SG_ID"
        
        # Run full pipeline task
        echo "Starting full pipeline task..."
        TASK_ARN=$(aws ecs run-task \
          --cluster "$CLUSTER_NAME" \
          --task-definition "$TASK_DEFINITION_FAMILY" \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_IDS],assignPublicIp=ENABLED,securityGroups=[$SG_ID]}" \
          --overrides "{\"containerOverrides\":[{\"name\":\"chess-glicko\",\"environment\":[{\"name\":\"PROCESS_MONTH\",\"value\":\"$TEST_MONTH\"},{\"name\":\"PIPELINE_MODE\",\"value\":\"full\"},{\"name\":\"S3_BUCKET\",\"value\":\"$S3_BUCKET_NAME\"}]}]}" \
          --query 'tasks[0].taskArn' \
          --output text)
        
        if [ -n "$TASK_ARN" ] && [ "$TASK_ARN" != "None" ]; then
          echo "✅ Full pipeline test started: $TASK_ARN"
          echo "This will run all pipeline steps including data downloading and scraping."
          echo "Monitor with: aws ecs describe-tasks --cluster $CLUSTER_NAME --tasks $TASK_ARN"
          
          # Wait a moment and check task status
          sleep 15
          TASK_STATUS=$(aws ecs describe-tasks \
            --cluster "$CLUSTER_NAME" \
            --tasks "$TASK_ARN" \
            --query 'tasks[0].lastStatus' \
            --output text)
          echo "Task status after 15 seconds: $TASK_STATUS"
          
          echo "⚠️  Note: Full pipeline test may take 15-20 minutes to complete"
          echo "Check CloudWatch logs for detailed progress: /ecs/chess-glicko"
        else
          echo "❌ Failed to start full pipeline test"
          exit 1
        fi

  test-post-scraping:
    needs: [deploy-infrastructure, build-and-deploy]
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'post_scraping'
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Validate Required Data Exists
      env:
        S3_BUCKET_NAME: ${{ needs.deploy-infrastructure.outputs.s3_bucket_name }}
      run: |
        echo "=== Validating Required Data for Post-Scraping Test ==="
        
        # Determine test month
        if [ -n "${{ github.event.inputs.test_month }}" ]; then
          TEST_MONTH="${{ github.event.inputs.test_month }}"
        else
          TEST_MONTH=$(date -d "$(date +'%Y-%m-01') -1 month" +'%Y-%m')
        fi
        
        echo "Checking data for month: $TEST_MONTH"
        echo "S3 bucket: $S3_BUCKET_NAME"
        
        # Check if required data exists
        MISSING_DATA=""
        
        # Check if processed player data exists
        if ! aws s3 ls "s3://$S3_BUCKET_NAME/persistent/player_info/processed/$TEST_MONTH.txt" >/dev/null 2>&1; then
          MISSING_DATA="$MISSING_DATA\n- Player info processed data (persistent/player_info/processed/$TEST_MONTH.txt)"
        fi
        
        # Check if active players data exists for at least standard time control
        if ! aws s3 ls "s3://$S3_BUCKET_NAME/persistent/active_players/${TEST_MONTH}_standard.txt" >/dev/null 2>&1; then
          MISSING_DATA="$MISSING_DATA\n- Active players data (persistent/active_players/${TEST_MONTH}_standard.txt)"
        fi
        
        # Check if calculation data exists
        CALC_COUNT=$(aws s3 ls "s3://$S3_BUCKET_NAME/persistent/calculations/$TEST_MONTH/" --recursive | wc -l)
        if [ "$CALC_COUNT" -eq 0 ]; then
          MISSING_DATA="$MISSING_DATA\n- Calculation data (persistent/calculations/$TEST_MONTH/)"
        fi
        
        # Export for next step
        echo "TEST_MONTH=$TEST_MONTH" >> $GITHUB_ENV
        
        if [ -n "$MISSING_DATA" ]; then
          echo "❌ ERROR: Required data is missing for post-scraping test:"
          echo -e "$MISSING_DATA"
          echo ""
          echo "The post-scraping test requires that the following pipeline steps have been completed:"
          echo "1. Download player data"
          echo "2. Process player data"
          echo "3. Scrape and process tournament data"
          echo "4. Aggregate player IDs"
          echo "5. Scrape player calculations"
          echo ""
          echo "Please run the full pipeline first, or use test_type: 'full' to test all steps."
          exit 1
        else
          echo "✅ All required data found for post-scraping test"
          echo "Found calculation files: $CALC_COUNT"
        fi

    - name: Run Post-Scraping Pipeline Test
      env:
        CLUSTER_NAME: ${{ needs.deploy-infrastructure.outputs.ecs_cluster_name }}
        TASK_DEFINITION_FAMILY: ${{ needs.deploy-infrastructure.outputs.task_definition_family }}
        S3_BUCKET_NAME: ${{ needs.deploy-infrastructure.outputs.s3_bucket_name }}
      run: |
        echo "=== Running Post-Scraping Pipeline Test ==="
        echo "CLUSTER_NAME: '$CLUSTER_NAME'"
        echo "TASK_DEFINITION_FAMILY: '$TASK_DEFINITION_FAMILY'"
        echo "S3_BUCKET_NAME: '$S3_BUCKET_NAME'"
        echo "TEST_MONTH: '$TEST_MONTH'"
        
        # Fallback for cluster name if needed
        if [ -z "$CLUSTER_NAME" ]; then
          echo "⚠️  CLUSTER_NAME is empty, using default: chess-glicko-cluster"
          CLUSTER_NAME="chess-glicko-cluster"
        fi
        
        # Fallback for task definition family if needed
        if [ -z "$TASK_DEFINITION_FAMILY" ]; then
          echo "⚠️  TASK_DEFINITION_FAMILY is empty, using default: chess-glicko-task"
          TASK_DEFINITION_FAMILY="chess-glicko-task"
        fi
        
        # Get network configuration
        SUBNET_IDS=$(aws ec2 describe-subnets \
          --filters "Name=vpc-id,Values=$(aws ec2 describe-vpcs --filters 'Name=isDefault,Values=true' --query 'Vpcs[0].VpcId' --output text)" \
          --query 'Subnets[0:3].SubnetId' \
          --output text | tr '\t' ',')
        
        SG_ID=$(aws ec2 describe-security-groups \
          --filters "Name=group-name,Values=chess-glicko-ecs-tasks" \
          --query 'SecurityGroups[0].GroupId' \
          --output text 2>/dev/null || echo "")
        
        if [ -z "$SG_ID" ] || [ "$SG_ID" = "None" ]; then
          SG_ID=$(aws ec2 describe-security-groups \
            --filters "Name=group-name,Values=default" \
            --query 'SecurityGroups[0].GroupId' \
            --output text)
        fi
        
        echo "Using subnets: $SUBNET_IDS"
        echo "Using security group: $SG_ID"
        
        # Run post-scraping pipeline task
        echo "Starting post-scraping pipeline task..."
        TASK_ARN=$(aws ecs run-task \
          --cluster "$CLUSTER_NAME" \
          --task-definition "$TASK_DEFINITION_FAMILY" \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_IDS],assignPublicIp=ENABLED,securityGroups=[$SG_ID]}" \
          --overrides "{\"containerOverrides\":[{\"name\":\"chess-glicko\",\"environment\":[{\"name\":\"PROCESS_MONTH\",\"value\":\"$TEST_MONTH\"},{\"name\":\"PIPELINE_MODE\",\"value\":\"post_scraping\"},{\"name\":\"S3_BUCKET\",\"value\":\"$S3_BUCKET_NAME\"}]}]}" \
          --query 'tasks[0].taskArn' \
          --output text)
        
        if [ -n "$TASK_ARN" ] && [ "$TASK_ARN" != "None" ]; then
          echo "✅ Post-scraping pipeline test started: $TASK_ARN"
          echo "This will run only the post-scraping steps:"
          echo "- Process calculation data"
          echo "- Calculate ratings"
          echo "- Upload results"
          echo ""
          echo "Monitor with: aws ecs describe-tasks --cluster $CLUSTER_NAME --tasks $TASK_ARN"
          
          # Wait a moment and check task status
          sleep 15
          TASK_STATUS=$(aws ecs describe-tasks \
            --cluster "$CLUSTER_NAME" \
            --tasks "$TASK_ARN" \
            --query 'tasks[0].lastStatus' \
            --output text)
          echo "Task status after 15 seconds: $TASK_STATUS"
          
          echo "⚠️  Note: Post-scraping test should complete in 2-5 minutes"
          echo "Check CloudWatch logs for detailed progress: /ecs/chess-glicko"
        else
          echo "❌ Failed to start post-scraping pipeline test"
          exit 1
        fi